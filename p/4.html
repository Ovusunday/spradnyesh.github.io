<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
    <meta charset="utf-8"/>
    <title>Today is better than yesterday!</title>
    <link rel="canonical" href="http://spradnyesh.github.io">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link href='http://fonts.googleapis.com/css?family=Alegreya:400italic,700italic,400,700' rel='stylesheet'
          type='text/css'>
    <link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/bootstrap/3.3.0/css/bootstrap.min.css">
    <link href="//maxcdn.bootstrapcdn.com/font-awesome/4.2.0/css/font-awesome.min.css" rel="stylesheet">
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/8.1/styles/default.min.css">
    <link href="/css/screen.css" rel="stylesheet" type="text/css" />
</head>
<body>


<nav class="navbar navbar-default">
    <div class="container">
        <div class="navbar-header">
            <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="/index.html">Today is better than yesterday!</a>
        </div>
        <div id="navbar" class="navbar-collapse collapse">
            <ul class="nav navbar-nav navbar-right">
                <li ><a href="/index.html">Home</a></li>
                <li
                ><a href="/archives.html">Archives</a></li>
                
                <li
                >
                <a href="/pages/resume.html">Resume</a>
                </li>
                
                <li><a href="/feed.xml">RSS</a></li>
            </ul>
        </div><!--/.nav-collapse -->
    </div><!--/.container-fluid -->
</nav>


<div class="container">


    <div class="row">
        <div class="col-lg-9">
            <div id="content">
                
<div id="post">
    
    <div class="post-header">
        <h2>ml-401: Multivariate Linear Regression</h2>
        <div id="post-meta">
            
            <div class="date">February 1, 2014</div>
        </div>
    </div>
    <p>Hi! In the last <a href="http://www.golb.in/ml-305-univariate-linear-regression-43.html" shape="rect">post</a>, we completed learning our very first machine learning algorithm, viz "linear regression". As you might remember from <a href="http://www.golb.in/ml-102-supervised-learning-34.html" shape="rect">here</a>, this is a type of "supervised learning" ML algorithm. However, during our study, we had only 1 feature (or input variable), so that what we learnt was really the "univariate linear regression". Today we will take a look at how to handle a more real life situation, that is when we have more than one feature. Such an algorithm is called the "multivariate linear regression" ML algorithm.</p><p>To recap, for univariate linear regression, the steps were:</p>
    <a href="/posts/2014-02-01-ml-401-multivariate-linear-regression.html">Continue reading &#8594;</a>
    <hr>
    
    <div class="post-header">
        <h2>ml-305: Univariate Linear Regression</h2>
        <div id="post-meta">
            
            <div class="date">January 30, 2014</div>
        </div>
    </div>
    <p>In the last posts <a href="http://www.golb.in/ml-303-gradient-descent-41.html" shape="rect">here</a> and <a href="http://www.golb.in/ml-304-gradient-descent-and-learning-rate-%CE%B1-42.html" shape="rect">here</a>, we looked in much depth at the "gradient descent" minimization algorithm. Today we will complete the puzzle by fitting that last piece in the whole jigsaw of the "univariate linear regression" ML algorithm that we have been studying in this 30x series.</p><p>To do that, lets recap what we have learnt so far:</p>
    <a href="/posts/2014-01-30-ml-305-univariate-linear-regression.html">Continue reading &#8594;</a>
    <hr>
    
    <div class="post-header">
        <h2>ml-304: Gradient Descent and Learning Rate</h2>
        <div id="post-meta">
            
            <div class="date">January 29, 2014</div>
        </div>
    </div>
    <p>Hi. In the last <a href="http://www.golb.in/ml-303-gradient-descent-41.html" shape="rect">post</a>, we learnt about the "gradient descent" algorithm that is used to minimize our cost function "J(Θ<sub>0</sub>, Θ<sub>1</sub>)". Gradient descent algorithm was defined as:</p><pre><code>repeat until convergence {
  Θj = Θj - α δ/δΘj J(Θ0, Θ1) (for j = 0, 1)
}
</code></pre>
    <a href="/posts/2014-01-29-ml-304-gradient-descent-and-learning-rate.html">Continue reading &#8594;</a>
    <hr>
    
    <div class="post-header">
        <h2>ml-303: Gradient Descent</h2>
        <div id="post-meta">
            
            <div class="date">January 28, 2014</div>
        </div>
    </div>
    <p>Hi, welcome back! I hope you have been following our machine learning algorithm series in the last few posts. If you have, then you know that till now we have developed the basic framework for a particular algorithm called "univariate linear regression" and the only step pending is to minimize our cost function "J(Θ<sub>0</sub>, Θ<sub>1</sub>)" so that we can find the optimal values of Θ<sub>0</sub> and Θ<sub>1</sub>. Once we have these values, we can substitute them and arrive at the definition of our hypothesis function "h(x)" which will let us predict the values for our target variable "y".</p><p>I hope that things are clear till here. If they are, then lets move on to our last and final step of the algorithm, that is to minimize our cost function "J(Θ<sub>0</sub>, Θ<sub>1</sub>)". The general outline of the steps that we will follow to achieve this are:</p>
    <a href="/posts/2014-01-28-ml-303-gradient-descent.html">Continue reading &#8594;</a>
    <hr>
    
    <div class="post-header">
        <h2>ml-302: Intuition for Linear Regression</h2>
        <div id="post-meta">
            
            <div class="date">January 27, 2014</div>
        </div>
    </div>
    <p>Hello! Welcome back. Last time we studied the "univariate linear regression" ML algorithm <a href="http://www.golb.in/ml-301-linear-regression-with-one-variable-38.html" shape="rect">here</a>. That time we took in a lot of new concepts, and not everything might be clear to all. So today we will dig a bit deeper into the various components and try to understand how and why they work correctly. This will help us analyze if our implementation is working correctly and also to debug things if it is not.</p><p>So lets begin with a quick review. First, the terminology</p>
    <a href="/posts/2014-01-27-ml-302-intuition-for-univariate-linear-regression.html">Continue reading &#8594;</a>
    <hr>
    

    <div id="prev-next">
        
        <a class="left" href="/p/3.html">&laquo; Prev</a>
        
        
        <a class="right" href="/p/5.html">Next &raquo;</a>
        
    </div>
</div>

            </div>
        </div>

        <div class="col-md-3">
            <div id="sidebar">
                <!--<h3>Links</h3>
                <ul id="links">
                    <li><a href="http://cryogenweb.org/docs/home.html">Cryogen Docs</a></li>
                    <li><a href="http://carmenla.me/blog/archives">Carmen's Blog</a></li>
                    
                </ul>-->
                
                <div id="recent">
                    <h3>Recent Posts</h3>
                    <ul>
                        
                        <li><a href="/posts/2016-07-08-default-value-for-input-when-using-reagent.html">Issue w/ default-value using reagent and rendering multiple times</a></li>
                        
                        <li><a href="/posts/2016-06-11-cryogen-on-github.html">cryogen based static site on github</a></li>
                        
                        <li><a href="/posts/2016-06-11-lightdm-passwordless-login.html">passwordless login in lightdm</a></li>
                        
                        <li><a href="/posts/2014-02-19-ml-506-multi-class-classification.html">ml-506: Multi-class Classification</a></li>
                        
                        <li><a href="/posts/2014-02-18-ml-505-simplified-cost-function-and-gradient-descent-for-logistic-regression.html">ml-505: Simplified Cost Function and Gradient Descent for Logistic Regression</a></li>
                        
                        <li><a href="/posts/2014-02-17-ml-504-cost-function-for-logistic-regression.html">ml-504: Cost Function and Logistic Regression</a></li>
                        
                        <li><a href="/posts/2014-02-10-ml-503-non-linear-decision-boundary.html">ml-503: Non Linear Decision Boundary</a></li>
                        
                        <li><a href="/posts/2014-02-09-ml-502-hypothesis-representation-and-decision-boundary.html">ml-502: Hypothesis Representation and Decision Boundary</a></li>
                        
                        <li><a href="/posts/2014-02-08-ml-501-logistic-regression.html">ml-501: Logistic Regression</a></li>
                        
                        <li><a href="/posts/2014-02-07-ml-406-normal-equation-part-2.html">ml-406: Normal Equation -- part - 2</a></li>
                        
                    </ul>
                </div>
                
                
                <div id="tags">
                    <h3>Tags</h3>
                    <ul>
                        
                        <li><a href="/cryogen.html">cryogen</a></li>
                        
                        <li><a href="/passwordless.html">passwordless</a></li>
                        
                        <li><a href="/github.html">github</a></li>
                        
                        <li><a href="/clojure.html">clojure</a></li>
                        
                        <li><a href="/web.html">web</a></li>
                        
                        <li><a href="/hybrid.html">hybrid</a></li>
                        
                        <li><a href="/linux.html">linux</a></li>
                        
                        <li><a href="/frontend.html">frontend</a></li>
                        
                        <li><a href="/static-site.html">static-site</a></li>
                        
                        <li><a href="/reagent.html">reagent</a></li>
                        
                        <li><a href="/lightdm.html">lightdm</a></li>
                        
                        <li><a href="/app.html">app</a></li>
                        
                        <li><a href="/render.html">render</a></li>
                        
                        <li><a href="/mobile.html">mobile</a></li>
                        
                        <li><a href="/login.html">login</a></li>
                        
                        <li><a href="/react.html">react</a></li>
                        
                        <li><a href="/stumpwm.html">stumpwm</a></li>
                        
                    </ul>
                </div>
                
            </div>
        </div>
    </div>
    <footer>Copyright &copy;  Pradnyesh Sawant
        <p style="text-align: center;">Powered by <a href="http://cryogenweb.org">Cryogen</a></p></footer>
</div>
<script src="//code.jquery.com/jquery-1.11.0.min.js"></script>
<script src="//maxcdn.bootstrapcdn.com/bootstrap/3.3.0/js/bootstrap.min.js"></script>
<script type="text/javascript" src="https://ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/gist-embed/2.4/gist-embed.min.js"></script>
<script src="/js/highlight.pack.js" type="text/javascript"></script>
<script>hljs.initHighlightingOnLoad();</script>
</body>
</html>
