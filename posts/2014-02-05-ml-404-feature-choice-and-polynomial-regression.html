<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
    <meta charset="utf-8"/>
    <title>Today is better than yesterday!: ml-404: Feature Choice and Polynomial Regression</title>
    <link rel="canonical" href="http://spradnyesh.github.io/posts/2014-02-05-ml-404-feature-choice-and-polynomial-regression.html">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link href='http://fonts.googleapis.com/css?family=Alegreya:400italic,700italic,400,700' rel='stylesheet'
          type='text/css'>
    <link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/bootstrap/3.3.0/css/bootstrap.min.css">
    <link href="//maxcdn.bootstrapcdn.com/font-awesome/4.2.0/css/font-awesome.min.css" rel="stylesheet">
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/8.1/styles/default.min.css">
    <link href="/css/screen.css" rel="stylesheet" type="text/css" />
</head>
<body>


<nav class="navbar navbar-default">
    <div class="container">
        <div class="navbar-header">
            <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="/index.html">Today is better than yesterday!</a>
        </div>
        <div id="navbar" class="navbar-collapse collapse">
            <ul class="nav navbar-nav navbar-right">
                <li ><a href="/index.html">Home</a></li>
                <li
                ><a href="/archives.html">Archives</a></li>
                
                <li
                >
                <a href="/pages/resume.html">Resume</a>
                </li>
                
                <li><a href="/feed.xml">RSS</a></li>
            </ul>
        </div><!--/.nav-collapse -->
    </div><!--/.container-fluid -->
</nav>


<div class="container">


    <div class="row">
        <div class="col-lg-9">
            <div id="content">
                
<div id="post">
    <div class="post-header">
    <div id="post-meta" class="row">
        <div class="col-lg-6">February 5, 2014</div>
        
    </div>
    <h2>ml-404: Feature Choice and Polynomial Regression</h2>
</div>
<div>
    
    <p>Hi. It's good to see you once more. Today we will learn a particular technique to choose features that might improve the performance (in terms of prediction accuracy) of the regression algorithm, and in turn look at a subset type of regression that results from it.</p><p>In one of the initial <a href='http://www.golb.in/ml-301-linear-regression-with-one-variable-38.html'>posts</a>&nbsp;when we started learning the linear regression ML algorithm, we had used the following data</p><p><table class="table table-bordered"> <tbody> <tr> <td> size in ft<sup>2</sup> (x)</td> <td> price ($) in 1000's (y)</td> </tr> <tr> <td> 2104</td> <td> 460</td> </tr> <tr> <td> 1416</td> <td> 232</td> </tr> <tr> <td> 1534</td> <td> 315</td> </tr> <tr> <td> 852</td> <td> 178</td> </tr> <tr> <td> &hellip;</td> <td> &hellip;</td> </tr> </tbody> </table></p><p>and called our problem as the "housing prediction" problem. This particular problem is the "univariate" type of linear regression because we have only 1 input feature, viz the size of the house in sq-ft.</p><p>However, it is very easy to assume that we might have got our input features in the form of "length" and "depth", that is as x<sub>1</sub> and x<sub>2</sub> instead. But, maybe, we had some background domain knowledge to know that the price of the house is <i>more</i> dependent on the area (length * depth), instead of the individual features of length and depth themselves. So in this case, it's like we created a new feature x<sub>3</sub></p><blockquote><p> x<sub>3</sub> = x<sub>1</sub> * x<sub>2</sub>; </p></blockquote><p>and used it in place of x<sub>1</sub> and x<sub>2</sub>. Maybe, we also knew, due to domain knowledge, that given the area (x<sub>3</sub>), the features of length (x<sub>1</sub>) and depth (x<sub>2</sub>) do not play any significant role in the prediction of the price (y), and hence can be dropped; thus making y dependent only on x<sub>3</sub>.</p><p>The point to note here is that x<sub>3</sub> is no longer a simple variable/feature, but in fact is the product of 2 (x<sub>1</sub> and x<sub>2</sub>) simpler features. Thus, while the graph of x<sub>1</sub> versus y might have been linear, the graph of x<sub>3</sub> versus y would appear to have a quadratic shape (having some sort of a curved nature).</p><p>Similar effect (in terms of the graph plot) would appear if we would have used a polynomial power of the base variable itself. For example, if</p><blockquote><p> y = x<sub>1</sub> ^ 2; </p></blockquote><p>or</p><blockquote><p> y = x<sub>2</sub> ^ 3; </p></blockquote><p>etc, would give the curve of the input versus output variable a different shape.</p><p>![]()</p><p>![]()</p><p>![]()</p><p>Looking at the plots of your input versus output variable, you might get an idea a polynomial feature might be needed. In such cases, armed with some domain knowledge, if one can play with choosing the power of the input feature variables, it is possible to radically improve the performance (in terms of prediction accuracy, not speed) of our implementation.</p><p>Since, in these cases, we use a polynomial power of our input variable(s), these algorithms are also known as "polynomial regression" type of ML algorithms. Of course, if one has domain knowledge and already knows some relationship (although not exactly) between the input and output variables, then it can be extremely helpful.</p><p>In future posts we will take a look at some advanced algorithms which can automatically find out such relationships, and other algorithms which can automatically choose only those features which improve the performance of the implementation significantly and drop the others. So keep watching this space to learn about them :)</p>
</div>


    <div id="prev-next">
        
        <a href="/posts/2014-02-06-ml-405-normal-equation-part-1.html">&laquo; ml-405: Normal Equation -- part - 1</a>
        
        
        <a class="right" href="/posts/2014-02-04-ml-403-feature-scaling.html">ml-403: Feature Scaling &raquo;</a>
        
    </div>

    


</div>

            </div>
        </div>

        <div class="col-md-3">
            <div id="sidebar">
                <!--<h3>Links</h3>
                <ul id="links">
                    <li><a href="http://cryogenweb.org/docs/home.html">Cryogen Docs</a></li>
                    <li><a href="http://carmenla.me/blog/archives">Carmen's Blog</a></li>
                    
                </ul>-->
                
                <div id="recent">
                    <h3>Recent Posts</h3>
                    <ul>
                        
                        <li><a href="/posts/2016-06-11-cryogen-on-github.html">cryogen based static site on github</a></li>
                        
                        <li><a href="/posts/2016-06-11-lightdm-passwordless-login.html">passwordless login in lightdm</a></li>
                        
                        <li><a href="/posts/2014-02-19-ml-506-multi-class-classification.html">ml-506: Multi-class Classification</a></li>
                        
                        <li><a href="/posts/2014-02-18-ml-505-simplified-cost-function-and-gradient-descent-for-logistic-regression.html">ml-505: Simplified Cost Function and Gradient Descent for Logistic Regression</a></li>
                        
                        <li><a href="/posts/2014-02-17-ml-504-cost-function-for-logistic-regression.html">ml-504: Cost Function and Logistic Regression</a></li>
                        
                        <li><a href="/posts/2014-02-10-ml-503-non-linear-decision-boundary.html">ml-503: Non Linear Decision Boundary</a></li>
                        
                        <li><a href="/posts/2014-02-09-ml-502-hypothesis-representation-and-decision-boundary.html">ml-502: Hypothesis Representation and Decision Boundary</a></li>
                        
                    </ul>
                </div>
                
                
                <div id="tags">
                    <h3>Tags</h3>
                    <ul>
                        
                        <li><a href="/cryogen.html">cryogen</a></li>
                        
                        <li><a href="/github.html">github</a></li>
                        
                        <li><a href="/clojure.html">clojure</a></li>
                        
                        <li><a href="/static-site.html">static-site</a></li>
                        
                        <li><a href="/passwordless.html">passwordless</a></li>
                        
                        <li><a href="/linux.html">linux</a></li>
                        
                        <li><a href="/lightdm.html">lightdm</a></li>
                        
                        <li><a href="/login.html">login</a></li>
                        
                        <li><a href="/stumpwm.html">stumpwm</a></li>
                        
                    </ul>
                </div>
                
            </div>
        </div>
    </div>
    <footer>Copyright &copy;  Pradnyesh Sawant
        <p style="text-align: center;">Powered by <a href="http://cryogenweb.org">Cryogen</a></p></footer>
</div>
<script src="//code.jquery.com/jquery-1.11.0.min.js"></script>
<script src="//maxcdn.bootstrapcdn.com/bootstrap/3.3.0/js/bootstrap.min.js"></script>
<script src="/js/highlight.pack.js" type="text/javascript"></script>
<script>hljs.initHighlightingOnLoad();</script>
</body>
</html>
