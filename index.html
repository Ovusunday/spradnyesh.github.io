<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
    <meta charset="utf-8"/>
    <title>Today is better than yesterday!</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link href='http://fonts.googleapis.com/css?family=Alegreya:400italic,700italic,400,700' rel='stylesheet'
          type='text/css'>
    <link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/bootstrap/3.3.0/css/bootstrap.min.css">
    <link href="//maxcdn.bootstrapcdn.com/font-awesome/4.2.0/css/font-awesome.min.css" rel="stylesheet">
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/8.1/styles/default.min.css">
    <link href="css/screen.css" rel="stylesheet" type="text/css" />
</head>
<body>


<nav class="navbar navbar-default">
    <div class="container">
        <div class="navbar-header">
            <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="/index.html">Today is better than yesterday!</a>
        </div>
        <div id="navbar" class="navbar-collapse collapse">
            <ul class="nav navbar-nav navbar-right">
                <li  class="active" ><a href="/index.html">Home</a></li>
                <li
                ><a href="/archives.html">Archives</a></li>
                
                <li><a href="/feed.xml">RSS</a></li>
            </ul>
        </div><!--/.nav-collapse -->
    </div><!--/.container-fluid -->
</nav>


<div class="container">


    <div class="row">
        <div class="col-lg-9">
            <div id="content">
                
<div id="post">
    <div class="post-header">
    <div id="post-meta" class="row">
        <div class="col-lg-6">19 February, 2014</div>
        
    </div>
    <h2>ml-506: Multi-class Classification</h2>
</div>
<div>
    </ol class="contents">
    <p>Hello and welcome back! Previously, we have discussed the various aspects in much detail in these posts <a href='http://www.golb.in/ml-501-logistic-regression-51.html'>here</a>, <a href='http://www.golb.in/ml-502-hypothesis-representation-and-decision-boundary-52.html'>here</a>, <a href='http://www.golb.in/ml-503-non-linear-decision-boundary-53.html'>here</a>, <a href='http://www.golb.in/ml-504-cost-function-for-logistic-regression-54.html'>here</a> and <a href='http://www.golb.in/ml-505-simplified-cost-function-and-gradient-descent-for-logistic-regression-55.html'>here</a>. Today we will look at the final topic in classification ML algorithms, viz multi-class classification.</p><p>Before starting with the actual algorithm, let us first take a look at some examples of multi-classes to ensure that our understanding about them is correct:</p><ul><li>email foldering/tagging: work (y = 1), friends (y = 2), family (y = 3), hobby (y = 4)</li><li>medical diagnosis: not ill (y = 1), cold (y = 2), flu (y = 3)</li><li>weather: sunny (y = 1), cloudy (y = 2), rain (y = 3), snow (y = 4)</li></ul><p>![]()</p><p>In all of the above examples, the output variable "y" takes on values from a discrete set (size greater than 2), instead of just "0" and "1" (as in binary classification). This is the problem statement multi-class classification. Note that it does not matter whether the class index starts from 0 or 1.</p><p>The technique that is used to solve multi-class classification problems is known as the "one vs all" (or "one vs rest") algorithm. Let us say that our multi-class classification problem has "k" classes (where, k &gt; 2). Then, in "one vs all" classification technique, we take only one class at a time and combine all the other classes into a single class; thus turning the k-class classification problem into k binary classification problems as shown in below graphs</p><p>![]()</p><p>![]()</p><p>![]()</p><p>Then we will get k hypothesis functions as below:</p><blockquote><p> h<sub>&theta;</sub><sup>(i)</sup>(x) = p(y = i|x; &theta;), where i = 1, 2, &hellip;, k </p></blockquote><p>The actual prediction (finding y) is done as follows:</p><blockquote><p> y = i, where class i is one that maximizes h<sub>&theta;</sub><sup>(i)</sup>(x) </p></blockquote><p>This completes our <a href='http://www.golb.in/tag/50x/'>50x</a> series of ML algorithms which dealt with the topic of classification or logistic regression. I hope you have been following me till now and have enjoyed reading and learning as much as I have writing it and learning from it too :) Do share your thoughts on how I can improve this series further by leaving comments below.</p><p>From the next time we will move onto more complex topics and delve much deeper into the realm of ML algorithms. So do come back and enjoy :)</p>
</div>


    

    <div id="prev-next">
        
        
        <a class="right" href="/posts/2014-02-18-ml-505-simplified-cost-function-and-gradient-descent-for-logistic-regression.html">ml-505: Simplified Cost Function and Gradient Descent for Logistic Regression &raquo;</a>
        
    </div>
</div>

            </div>
        </div>

        <div class="col-md-3">
            <div id="sidebar">
                <h3>Links</h3>
                <ul id="links">
                    <li><a href="http://cryogenweb.org/docs/home.html">Cryogen Docs</a></li>
                    <li><a href="http://carmenla.me/blog/index.html">Carmen's Blog</a></li>
                    
                </ul>
                
                <div id="recent">
                    <h3>Recent Posts</h3>
                    <ul>
                        
                        <li><a href="/posts/2014-02-19-ml-506-multi-class-classification.html">ml-506: Multi-class Classification</a></li>
                        
                        <li><a href="/posts/2014-02-18-ml-505-simplified-cost-function-and-gradient-descent-for-logistic-regression.html">ml-505: Simplified Cost Function and Gradient Descent for Logistic Regression</a></li>
                        
                        <li><a href="/posts/2014-02-17-ml-504-cost-function-for-logistic-regression.html">ml-504: Cost Function and Logistic Regression</a></li>
                        
                    </ul>
                </div>
                
                
            </div>
        </div>
    </div>
    <footer>Copyright &copy; 2015 Pradnyesh Sawant
        <p style="text-align: center;">Powered by <a href="http://cryogenweb.org">Cryogen</a></p></footer>
</div>
<script src="//code.jquery.com/jquery-1.11.0.min.js"></script>
<script src="//maxcdn.bootstrapcdn.com/bootstrap/3.3.0/js/bootstrap.min.js"></script>
<script src="js/highlight.pack.js" type="text/javascript"></script>
<script>hljs.initHighlightingOnLoad();</script>
</body>
</html>
